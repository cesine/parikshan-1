Software debugging is the process of localizing, and finding defects that were observed in a system.
In a world of increasingly complex and large scale distributed systems, errors can be very subtle, and can have a compounded impact on the application.
%Owing to high instrumentation overheads, and potential crashes in the debugging environment during the debugging process, debugging is usually done in the development environment.
%Existing Testing and Verification technologies, are impractical for testing large scale softwares.
Unfortunately, replicating production bugs of complex large scale systems in an offline environment continues to be a substantial challenge.
In particular, production systems bugs can be a result of complex interactions between multiple system components, and can cause faults either in the kernel, middleware or the application itself.
Hence it is important, to be able to gain insight in the entire workflow of the system, both breadth-wise (across application tiers and network boundaries), and depth wise (across the execution stack from application to kernel).

In addition to the inherent complexity in software debugging, it is also essential to have a short time to bug diagnosis to reduce the financial impact of any error.
Recent trends towards DevOps\cite{devops}, and Agile\cite{agile} software engineering paradigms further emphasize the need to having shorter debug cycles.
DevOps stresses on close coupling between software developers and operators, and to merge the operations of both.
Most companies which have adopted DevOps have very frequent releases and hence require a very short time to a bug fix, test, patch and release in order to realize continuous delivery (Facebook mobile has 2 releases a day, and Flickr has 10 deployment cycles per day).
Similarly agile programming has shorter development cycles called \textit{sprints}, which focus on faster releases, and quick debugging.

Existing debugging mechanisms allow on light-weight instrumentation which tracks execution flow in the application by instrumenting important points of execution.
These are followed by inference based mechanisms to find the root-cause of the problem.
Unfortunately, these techniques are usually used to provide a clue towards the bug, and might not be able to localize the error.
Another body of work uses record-and-replay infrastructures, which record the execution and then replay the execution offline.
While record and replay infrastructures generate a high fidelity representative framework for bug diagnosis, they suffer a heavy overhead generally not acceptable in user-facing production systems.

In order to meet the demands of a low-latency distributed computing environment of modern service oriented systems, it is important to have debugging tools which have \textit{minimal to negligible impact} on the application, and can provide a fast update to the operator to allow for \textit{shorter time to debug}.
In order to meet this goals, we introduce a new debugging paradigm called \livedebugging.
There are two goals that any \livedebugging infrastructure must meet:
Firstly, it must offer real-time insight and bug diagnosis and localization, which is paramount when errors happen in service-oriented-application. 
Several modern day 24*7 applications have developers serving as operators who are available in \textit{shifts} at all times to tackle any problems that occur in the system.
Having a shorter debug cycles and quicker patches is essential to ensure application quality, reliability and reduce the financial impact on the application.
Secondly, \livedebugging should not impact user-facing performance for non bug triggering events.
In large distributed applications, non-crashing bugs which impact only a small percentage of users are common. 
In such scenarios, debugging a small part of the application should not impact the entire system.

With the above stated goals in mind, we have designed a platform called \parikshan, which leverages user-space containers (OpenVZ/ LXC) to launch application instances for the express purpose of \livedebugging. 
\parikshan is driven by a  live-cloning process, which generates a \debugcontainer for debugging or testing, cloned from a \productioncontainer, which provides the real output to the user.
This \debugcontainer provides a sandbox environment, for safe execution of test-cases/debugging done by the users without any perturbation to the execution environment.
%Our sandboxes have independent network name-spaces, and resource management for the processes executing the test/debug cases.
As a part of this framework, we have designed customized-network proxy agents, which replicate inputs from clients to both the production and test-container, as well safely discard all outputs from the test-container.
Together the network proxy, and the debug container ensure both compute and network isolation of the debugging environment, while at the same time allowing the user to debug the application.
As a part of this thesis, we have also looked into \textit{light-weight instrumentation techniques}, which can complement our \livedebugging environment.
Additionally, we will demonstrate a \textit{statistical debugging mechanism} that can be applied in the debug-container to gain insight and localize the error in real-time. 
We believe that this piece of work provides the first of it's kind practical real-time debugging of large multi-tier and cloud applications, without requiring any application down-time, and minimal performance impact.

%Further, we look towards analysis for guided debugging in a live debugging environment as created in \parikshan.
%We explain the debugging workflow from an end-to-end basis for an application debugger.
%First we try and briefly answer how existing approaches can be used to localize the components that need to be cloned, using readily available log information.
%We look into our earlier work called \textit{CLUE}\cite{clue} where we have explored systematically pointing potentially faulty components by looking at system call logs.
%We also show other works, which look at existing available transaction and error logs, which can be used to find error traces, and localize buggy components.
%Next, we explore the concept of \textit{debugging windows} in \parikshan, which signify the length of time till which the cloned containers faithfully follow the original production application.
%We discuss how we can track, and predict the window sizes, and the amount of instrumentation budget that the debugger can employ, without causing a debug window collapse.
%Finally, we look at new debugging analytics which can be used with \parikshan.
%We take inspiration from existing work in adaptive statistical profiling, speculative and delta-debugging techniques to generate traces with good and bad behavior.
%We show how automated debugging in \parikshan can greatly simplify the debugging process\
%We also look into how to make applications \parikshan ready, by adding ready to instrument hooks in the application code.
%In this context, we discuss \iprobe, a novel dynamic instrumentation technique, which allows for patching and instrumentation at runtime.
%\iprobe has a significant performance advantage on existing techniques, which use interrupt based mechanisms to insert trampolines for instrumentation in the kernel code.

The principal hypothesis of this dissertation is that, for large-scale service-oriented-applications(SOA) it is possible to provide a \livedebugging environment, which allows the developer to debug the target application without impacting the performance of the production system.
Primarily, we will present an approach for \livedebugging of production systems.
This involves discussion of \parikshan framework which forms the backbone of this dissertation.
We will discuss how to clone the containers, split and isolate network traffic, and aggregate it for communication to both upstream and downstream tiers, in a multi-tier SOA infrastructure.

Secondly, we will present \iprobe a new type of instrumentation framework, which uses a combination of static and dynamic instrumentation, to have an order-of-magnitude better performance than existing instrumentation techniques. 
While \livedebugging does not put any performance impact on the production, it is still important to have the debug-container as much in sync with the production container as possible. 
\iprobe makes applications live debugging friendly, and provides an easy way for the debuggers to apply probes in the debugging sandboxed environment.

Thirdly, we will present a mechanism to create overhead budgets for instrumentation in the debug container to make \livedebugging more robust, and longer lasting.
This will be split in two different kinds of techniques: Firstly, we will provide pro-active mechanism to find an instrumentation overhead budget. This is based on queuing theory, simulations, and testing results. 
Secondly: we will provide a reactive mechanism to modify instrumentation overhead. 
We will use the buffer size and usage as a trigger and present novel sampling techniques together with statistical testing mechanism to effectively isolate bugs.

Lastly, while \parikshan is an platform to quickly attack bugs, in itself it's a debugging platform. For the last section of our dissertation we look at how various existing debugging techniques can be adapted to \livedebugging, making it more effective. We compare a variety of techniques and compare how they traditionally work and how they can be more effective with \parikshan. As a part of this we will demonstrate \activedebugging, which will allow developers to apply patches/fix or do testing in parallel to the production container.

%Third, we will describe a set of \emph{guidelines} that can be followed by developers to assist in the formulation and development of \livedebugging friendly applications.
%These will add flags and triggers which can be used with the approaches above for a clean and assisted separation of the debugging container when cloned from the \productioncontainer.
%We will also talk about CLUE a cross-tier end-to-end tracing framework
